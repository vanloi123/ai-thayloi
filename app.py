import google.generativeai as genai
from flask import Flask, render_template, request, jsonify, session
import os
import json
from dotenv import load_dotenv
load_dotenv()

app = Flask(__name__)
# C·∫•u h√¨nh Session cho Flask
app.secret_key = os.urandom(24)
app.config['SESSION_TYPE'] = 'filesystem'
app.config['SESSION_PERMANENT'] = False

api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("Ch∆∞a thi·∫øt l·∫≠p GOOGLE_API_KEY trong Environment Variables!")

# --- LOGIC S·ª¨A ƒê·ªîI: B·ªè d√≤ng √©p bu·ªôc version c≈© ƒë·ªÉ tr√°nh l·ªói ---
# os.environ["GOOGLE_GENERATIVE_AI_API_VERSION"] = "v1beta" 

genai.configure(api_key=api_key)

# --- DEBUG: KI·ªÇM TRA MODEL C√ì S·∫¥N (Logic m·ªõi th√™m v√†o) ---
print("=========================================")
print("ƒêANG KI·ªÇM TRA K·∫æT N·ªêI V√Ä DANH S√ÅCH MODEL...")
try:
    available_models = []
    for m in genai.list_models():
        if 'generateContent' in m.supported_generation_methods:
            print(f"- T√¨m th·∫•y: {m.name}")
            available_models.append(m.name)
            
    if not available_models:
        print("‚ùå C·∫¢NH B√ÅO: Kh√¥ng t√¨m th·∫•y model n√†o h·ªó tr·ª£ generateContent!")
    else:
        print("‚úÖ K·∫øt n·ªëi API th√†nh c√¥ng!")
except Exception as e:
    print(f"‚ùå L·ªñI K·∫æT N·ªêI NGHI√äM TR·ªåNG: {str(e)}")
print("=========================================")
# ---------------------------------------

# System Prompt 
system_prompt_global = (
    "B·∫°n l√† **Tr·ª£ gi·∫£ng S∆∞ ph·∫°m AI ƒêa m√¥n h·ªçc THPT**, c√≥ kinh nghi·ªám 20 nƒÉm ƒë·ª©ng l·ªõp. "
    "Phong c√°ch c·ªßa b·∫°n: X∆∞ng h√¥ l√† **'Th·∫ßy'** ho·∫∑c **'C√¥'**, gi·ªçng vƒÉn √¢n c·∫ßn, kh√≠ch l·ªá nh∆∞ng nghi√™m t√∫c v·ªÅ ki·∫øn th·ª©c.\n\n"

    "üéØ **M·ª§C TI√äU C·ªêT L√ïI:**\n"
    "Gi√∫p h·ªçc sinh **'H·ªçc ƒë·ªÉ hi·ªÉu ‚Äì Hi·ªÉu ƒë·ªÉ l√†m ƒë∆∞·ª£c'**. Tuy·ªát ƒë·ªëi KH√îNG ƒë∆∞a ƒë√°p √°n ngay, m√† h√£y d√πng ph∆∞∆°ng ph√°p Socratic (h·ªèi g·ª£i m·ªü) ƒë·ªÉ h·ªçc sinh t·ª± nh·∫≠n ra v·∫•n ƒë·ªÅ.\n\n"
    
    "‚ö†Ô∏è **QUY T·∫ÆC K·ª∏ THU·∫¨T B·∫ÆT BU·ªòC (QUAN TR·ªåNG V·ªöI MODEL GEMMA):**\n"
    "1. **TO√ÅN/L√ù/H√ìA:** B·∫Øt bu·ªôc d√πng m√£ **LaTeX** chu·∫©n cho m·ªçi bi·ªÉu th·ª©c.\n"
    "   - C√¥ng th·ª©c c√πng d√≤ng: k·∫πp trong `$ ... $` (V√≠ d·ª•: ph∆∞∆°ng tr√¨nh $x^2 - 4 = 0$).\n"
    "   - C√¥ng th·ª©c ri√™ng d√≤ng: k·∫πp trong `$$ ... $$`.\n"
    "   - KH√îNG d√πng k√Ω t·ª± unicode (kh√¥ng vi·∫øt x¬≤, ph·∫£i vi·∫øt $x^2$).\n"
    "2. **VƒÇN/S·ª¨/ƒê·ªäA:** Tr√¨nh b√†y m·∫°ch l·∫°c, in ƒë·∫≠m c√°c t·ª´ kh√≥a quan tr·ªçng.\n\n"

    "üìù **QUY TR√åNH PH·∫¢N H·ªíI (2 PH·∫¶N):**\n\n"
    
    "## PH·∫¶N 1: T∆Ø∆†NG T√ÅC S∆Ø PH·∫†M\n"
    "1. **Ph√¢n lo·∫°i:** B·∫Øt ƒë·∫ßu b·∫±ng `Ph√¢n lo·∫°i: M√¥n [M√¥n] ‚Äì [Ch·ªß ƒë·ªÅ] ‚Äì [C·∫•p ƒë·ªô]`.\n"
    "2. **Gi·∫£i th√≠ch/G·ª£i m·ªü:** ƒêi t·ª´ng b∆∞·ªõc. N·∫øu h·ªçc sinh h·ªèi b√†i t·∫≠p, h√£y h·ªèi ng∆∞·ª£c l·∫°i: 'Em ƒëang v∆∞·ªõng ·ªü b∆∞·ªõc n√†o?' ho·∫∑c g·ª£i √Ω b∆∞·ªõc ƒë·∫ßu ti√™n.\n"
    "3. **Th√°i ƒë·ªô:** Lu√¥n ƒë·ªông vi√™n (V√≠ d·ª•: 'C√¢u h·ªèi r·∫•t hay!', 'C·ªë l√™n em, s·∫Øp ra r·ªìi!').\n\n"

    "## PH·∫¶N 2: D·ªÆ LI·ªÜU JSON (·∫®N ƒê·ªÇ APP ƒê·ªåC)\n"
    "Cu·ªëi c√πng, B·∫ÆT BU·ªòC tr·∫£ v·ªÅ block code n√†y (kh√¥ng th√™m l·ªùi d·∫´n):\n"
    "```json-data\n"
    "{\n"
    ' "progress_strong": "[Ch·ªß ƒë·ªÅ h·ªçc sinh l√†m t·ªët]",\n'
    ' "progress_weak": "[Ch·ªß ƒë·ªÅ c·∫ßn c·∫£i thi·ªán]",\n'
    ' "analytics_summary": "[Nh·∫≠n x√©t ng·∫Øn c·ªßa gi√°o vi√™n v·ªÅ t∆∞ duy c·ªßa h·ªçc sinh]",\n'
    ' "recommendations": ["[G·ª£i √Ω 1]", "[G·ª£i √Ω 2]", "[G·ª£i √Ω 3]"]\n'
    "}\n"
    "```"
)
# LOGIC S·ª¨A ƒê·ªîI: B·ªè ti·ªÅn t·ªë 'models/' v√† th√™m try-except ƒë·ªÉ b·∫Øt l·ªói
try:
    model = genai.GenerativeModel(
        model_name="gemma-3-27b-it" 
    )
except Exception:
    try:
        model = genai.GenerativeModel("gemma-3-27b")
    except Exception as e:
        print(f"‚ùå L·ªói kh·ªüi t·∫°o: {e}")

# Bi·∫øn to√†n c·ª•c l∆∞u phi√™n chat
chat_session = None

def get_chat_session():
    """Kh·ªüi t·∫°o ho·∫∑c tr·∫£ v·ªÅ phi√™n chat hi·ªán t·∫°i."""
    global chat_session
    if 'chat_session_id' not in session or chat_session is None:
        chat_session = model.start_chat(history=[]) 
        session['chat_session_id'] = id(chat_session)   
    
    if 'learning_history' not in session:
        session['learning_history'] = []      
    return chat_session

@app.route("/")
def index():
    get_chat_session()
    return render_template("index.html")

@app.route("/new_chat", methods=["POST"])
def new_chat():
    """X·ª≠ l√Ω Reset khi ng∆∞·ªùi d√πng ch·ªçn m√¥n m·ªõi"""
    global chat_session
    chat_session = None 
    session.clear() 
    get_chat_session() 
    return jsonify({"status": "success", "message": "ƒê√£ reset h·ªôi tho·∫°i"})

@app.route("/ask", methods=["POST"])
def ask():
    user_message = request.json.get("message")
    if not user_message:
        return jsonify({"reply": "Vui l√≤ng nh·∫≠p c√¢u h·ªèi."})

    try:
        current_chat = get_chat_session()   
        
        # T√≥m t·∫Øt l·ªãch s·ª≠
        history_data = session.get('learning_history', [])
        recent_history = history_data[-3:] 
        
        history_str = "\n".join([f"H·ªçc sinh: {h['user']} | AI: {h['ai_summary']}" for h in recent_history])
        
        # --- K·ª∏ THU·∫¨T NH√öNG SYSTEM PROMPT V√ÄO TIN NH·∫ÆN ---
        # ƒê·ªÉ ƒë·∫£m b·∫£o ho·∫°t ƒë·ªông tr√™n c√°c phi√™n b·∫£n th∆∞ vi·ªán c≈© ch∆∞a h·ªó tr·ª£ system_instruction
        full_prompt = (
            f"{system_prompt_global}\n\n"
            f"=== L·ªäCH S·ª¨ H·ªòI THO·∫†I ===\n{history_str}\n\n"
            f"=== C√ÇU H·ªéI M·ªöI ===\n: {user_message}"
        )
        
        response = current_chat.send_message(full_prompt) 
        
        if not response.text:
             return jsonify({"reply": "L·ªói: AI kh√¥ng ph·∫£n h·ªìi."})       
        
        # L∆∞u v√†o l·ªãch s·ª≠ (L·ªçc b·ªè ph·∫ßn JSON)
        ai_reply_full = response.text
        clean_text_for_history = ai_reply_full.split("```json-data")[0].strip()
        
        if 'learning_history' not in session: session['learning_history'] = []
        session['learning_history'].append({
            'user': user_message,
            'ai_summary': clean_text_for_history[:150] + "..." 
        })
        session.modified = True 
        
        return jsonify({"reply": ai_reply_full})
        
    except Exception as e:
        print(f"Server Error: {e}")
        global chat_session
        chat_session = None 
        # Tr·∫£ v·ªÅ th√¥ng b√°o l·ªói th√¢n thi·ªán h∆°n
        return jsonify({"reply": f"‚ö†Ô∏è H·ªá th·ªëng ƒëang b·∫≠n ho·∫∑c g·∫∑p l·ªói k·∫øt n·ªëi API. M√£ l·ªói: {str(e)}"})

if __name__ == "__main__":

    app.run(host="0.0.0.0", port=5000, debug=True)


































